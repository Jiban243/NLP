{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f04085a-7773-49ad-8197-3ba1d9cc84ef",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce8883e5-0a97-4259-ab47-0f8d0555915a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete! Cleaned datasets saved.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# File paths\n",
    "train_path = \"train.json\"\n",
    "valid_path = \"valid.json\"\n",
    "test_path = \"test.json\"\n",
    "\n",
    "# Load JSON data\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_data = load_json(train_path)\n",
    "valid_data = load_json(valid_path)\n",
    "test_data = load_json(test_path)\n",
    "\n",
    "# Text Cleaning Function\n",
    "def clean_text(text):\n",
    "    \"\"\"Normalize text by removing special characters, fixing spacing, and correcting typos.\"\"\"\n",
    "    text = text.strip()  # Remove leading/trailing spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Normalize multiple spaces\n",
    "    text = re.sub(r\"!!+\", \"!\", text)  # Reduce multiple exclamation marks\n",
    "    text = text.replace(\"u \", \"you \").replace(\"muh \", \"my \")  # Fix informal text\n",
    "    return text\n",
    "\n",
    "# Dataset Preprocessing Function\n",
    "def preprocess_dataset(dataset):\n",
    "    \"\"\"Clean and structure the dataset.\"\"\"\n",
    "    processed_data = []\n",
    "    \n",
    "    for entry in dataset:\n",
    "        cleaned_entry = {\n",
    "            \"question\": clean_text(entry[\"question\"]),\n",
    "            \"answers\": [clean_text(ans) for ans in entry[\"answers\"]],\n",
    "            \"labelled_summary\": clean_text(entry[\"labelled_summaries\"].get(\"INFORMATION_SUMMARY\", \"\"))\n",
    "        }\n",
    "        processed_data.append(cleaned_entry)\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "# Apply cleaning\n",
    "cleaned_train = preprocess_dataset(train_data)\n",
    "cleaned_valid = preprocess_dataset(valid_data)\n",
    "cleaned_test = preprocess_dataset(test_data)\n",
    "\n",
    "# Save cleaned datasets\n",
    "def save_json(data, filename):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "save_json(cleaned_train, \"cleaned_train.json\")\n",
    "save_json(cleaned_valid, \"cleaned_valid.json\")\n",
    "save_json(cleaned_test, \"cleaned_test.json\")\n",
    "\n",
    "print(\"Preprocessing complete! Cleaned datasets saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a84be38d-8dee-4ca4-94ff-577b2a737b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete! Cleaned datasets saved.\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "train_path = \"train.json\"\n",
    "valid_path = \"valid.json\"\n",
    "test_path = \"test.json\"\n",
    "\n",
    "# Load JSON data\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_data = load_json(train_path)\n",
    "valid_data = load_json(valid_path)\n",
    "test_data = load_json(test_path)\n",
    "\n",
    "# Text Cleaning Function\n",
    "def clean_text(text):\n",
    "    \"\"\"Normalize text by removing special characters, fixing spacing, and correcting typos.\"\"\"\n",
    "    text = text.strip()  # Remove leading/trailing spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Normalize multiple spaces\n",
    "    text = re.sub(r\"!!+\", \"!\", text)  # Reduce multiple exclamation marks\n",
    "    text = text.replace(\"u \", \"you \").replace(\"muh \", \"my \")  # Fix informal text\n",
    "    return text\n",
    "\n",
    "# Dataset Preprocessing Function\n",
    "def preprocess_dataset(dataset):\n",
    "    \"\"\"Clean and structure the dataset.\"\"\"\n",
    "    processed_data = []\n",
    "    \n",
    "    for entry in dataset:\n",
    "        cleaned_entry = {\n",
    "            \"question\": clean_text(entry[\"question\"]),\n",
    "            \"answers\": [clean_text(ans) for ans in entry[\"answers\"]],\n",
    "            \"labelled_summary\": clean_text(entry[\"labelled_summaries\"].get(\"INFORMATION_SUMMARY\", \"\"))\n",
    "        }\n",
    "        processed_data.append(cleaned_entry)\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "# Apply cleaning\n",
    "cleaned_train = preprocess_dataset(train_data)\n",
    "cleaned_valid = preprocess_dataset(valid_data)\n",
    "cleaned_test = preprocess_dataset(test_data)\n",
    "\n",
    "# Save cleaned datasets\n",
    "def save_json(data, filename):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "save_json(cleaned_train, \"cleaned_train.json\")\n",
    "save_json(cleaned_valid, \"cleaned_valid.json\")\n",
    "save_json(cleaned_test, \"cleaned_test.json\")\n",
    "\n",
    "print(\"Preprocessing complete! Cleaned datasets saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5710772-72e9-4bcc-b1b2-6736413e6661",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab503807-37b9-4eb3-bf09-48ea38a1b4ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Questions Length Analysis:\n",
      "Max Length: 38\n",
      "95th Percentile: 29.0\n",
      "Mean Length: 16.15\n",
      "Median Length: 15.0\n",
      "\n",
      " Answers Length Analysis:\n",
      "Max Length: 512\n",
      "95th Percentile: 231.0\n",
      "Mean Length: 70.44\n",
      "Median Length: 44.0\n",
      "\n",
      " Summaries Length Analysis:\n",
      "Max Length: 398\n",
      "95th Percentile: 189.25\n",
      "Mean Length: 71.42\n",
      "Median Length: 59.0\n",
      "\n",
      "Tokenization complete! Tokenized datasets saved.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import BertTokenizer, T5Tokenizer\n",
    "\n",
    "# Load cleaned datasets\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_data = load_json(\"cleaned_train.json\")\n",
    "valid_data = load_json(\"cleaned_valid.json\")\n",
    "test_data = load_json(\"cleaned_test.json\")\n",
    "\n",
    "# Load Hugging Face Tokenizers\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Function to tokenize dataset\n",
    "def tokenize_dataset(dataset, tokenizer):\n",
    "    tokenized_data = []\n",
    "    question_lengths = []\n",
    "    answer_lengths = []\n",
    "    summary_lengths = []\n",
    "\n",
    "    for entry in dataset:\n",
    "        # Tokenize question\n",
    "        question_tokens = tokenizer(entry[\"question\"], truncation=True, padding=\"longest\")\n",
    "        question_lengths.append(len(question_tokens[\"input_ids\"]))\n",
    "\n",
    "        # Tokenize each answer\n",
    "        answer_tokens = [tokenizer(ans, truncation=True, padding=\"longest\") for ans in entry[\"answers\"]]\n",
    "        answer_lengths.extend([len(ans[\"input_ids\"]) for ans in answer_tokens])\n",
    "\n",
    "        # Tokenize summary\n",
    "        summary_tokens = tokenizer(entry[\"labelled_summary\"], truncation=True, padding=\"longest\")\n",
    "        summary_lengths.append(len(summary_tokens[\"input_ids\"]))\n",
    "\n",
    "        # Store tokenized results\n",
    "        tokenized_data.append({\n",
    "            \"question_tokens\": question_tokens[\"input_ids\"],\n",
    "            \"answers_tokens\": [ans[\"input_ids\"] for ans in answer_tokens],\n",
    "            \"summary_tokens\": summary_tokens[\"input_ids\"]\n",
    "        })\n",
    "\n",
    "    return tokenized_data, question_lengths, answer_lengths, summary_lengths\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_train, train_q_lens, train_a_lens, train_s_lens = tokenize_dataset(train_data, bert_tokenizer)\n",
    "tokenized_valid, valid_q_lens, valid_a_lens, valid_s_lens = tokenize_dataset(valid_data, bert_tokenizer)\n",
    "tokenized_test, test_q_lens, test_a_lens, test_s_lens = tokenize_dataset(test_data, bert_tokenizer)\n",
    "\n",
    "# Compute Length Statistics\n",
    "def compute_statistics(lengths, name):\n",
    "    print(f\"\\n {name} Length Analysis:\")\n",
    "    print(f\"Max Length: {np.max(lengths)}\")\n",
    "    print(f\"95th Percentile: {np.percentile(lengths, 95)}\")\n",
    "    print(f\"Mean Length: {np.mean(lengths):.2f}\")\n",
    "    print(f\"Median Length: {np.median(lengths)}\")\n",
    "\n",
    "# Analyze Lengths\n",
    "compute_statistics(train_q_lens, \"Questions\")\n",
    "compute_statistics(train_a_lens, \"Answers\")\n",
    "compute_statistics(train_s_lens, \"Summaries\")\n",
    "\n",
    "# Save Tokenized Data\n",
    "def save_json(data, filename):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "save_json(tokenized_train, \"tokenized_train.json\")\n",
    "save_json(tokenized_valid, \"tokenized_valid.json\")\n",
    "save_json(tokenized_test, \"tokenized_test.json\")\n",
    "\n",
    "print(\"\\nTokenization complete! Tokenized datasets saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d645c6-7674-4cf8-98e3-4d6b45d16cfc",
   "metadata": {},
   "source": [
    "# Token Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d1105e1-5e25-414a-957a-ddc4d460783f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Questions Token Length Analysis:\n",
      "Max Length: 38\n",
      "95th Percentile: 29.0\n",
      "Mean Length: 16.15\n",
      "Median Length: 15.0\n",
      "\n",
      " Answers Token Length Analysis:\n",
      "Max Length: 512\n",
      "95th Percentile: 231.0\n",
      "Mean Length: 70.44\n",
      "Median Length: 44.0\n",
      "\n",
      " Summaries Token Length Analysis:\n",
      "Max Length: 398\n",
      "95th Percentile: 189.25\n",
      "Mean Length: 71.42\n",
      "Median Length: 59.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load tokenized data\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "tokenized_train = load_json(\"tokenized_train.json\")\n",
    "tokenized_valid = load_json(\"tokenized_valid.json\")\n",
    "tokenized_test = load_json(\"tokenized_test.json\")\n",
    "\n",
    "# Extract token lengths\n",
    "train_q_lens = [len(entry[\"question_tokens\"]) for entry in tokenized_train]\n",
    "train_a_lens = [len(ans) for entry in tokenized_train for ans in entry[\"answers_tokens\"]]\n",
    "train_s_lens = [len(entry[\"summary_tokens\"]) for entry in tokenized_train]\n",
    "\n",
    "valid_q_lens = [len(entry[\"question_tokens\"]) for entry in tokenized_valid]\n",
    "valid_a_lens = [len(ans) for entry in tokenized_valid for ans in entry[\"answers_tokens\"]]\n",
    "valid_s_lens = [len(entry[\"summary_tokens\"]) for entry in tokenized_valid]\n",
    "\n",
    "test_q_lens = [len(entry[\"question_tokens\"]) for entry in tokenized_test]\n",
    "test_a_lens = [len(ans) for entry in tokenized_test for ans in entry[\"answers_tokens\"]]\n",
    "test_s_lens = [len(entry[\"summary_tokens\"]) for entry in tokenized_test]\n",
    "\n",
    "# Function to compute statistics\n",
    "def compute_statistics(lengths, name):\n",
    "    print(f\"\\n {name} Token Length Analysis:\")\n",
    "    print(f\"Max Length: {np.max(lengths)}\")\n",
    "    print(f\"95th Percentile: {np.percentile(lengths, 95)}\")\n",
    "    print(f\"Mean Length: {np.mean(lengths):.2f}\")\n",
    "    print(f\"Median Length: {np.median(lengths)}\")\n",
    "\n",
    "# Analyze token lengths\n",
    "compute_statistics(train_q_lens, \"Questions\")\n",
    "compute_statistics(train_a_lens, \"Answers\")\n",
    "compute_statistics(train_s_lens, \"Summaries\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73f30ca-b953-44f1-859c-1536b299147b",
   "metadata": {},
   "source": [
    "# Final Tokenization with Truncation & Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db71bcbb-d9db-442b-afa1-12080692cb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final tokenization complete! Processed datasets saved as PyTorch tensors.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, T5Tokenizer\n",
    "\n",
    "# Load cleaned datasets\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_data = load_json(\"cleaned_train.json\")\n",
    "valid_data = load_json(\"cleaned_valid.json\")\n",
    "test_data = load_json(\"cleaned_test.json\")\n",
    "\n",
    "# Load Hugging Face Tokenizers\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Truncation limits based on analysis\n",
    "MAX_LENGTH_QUESTION = 40\n",
    "MAX_LENGTH_ANSWER = 250\n",
    "MAX_LENGTH_SUMMARY = 190\n",
    "\n",
    "# Function to tokenize dataset with truncation & padding\n",
    "def tokenize_for_training(dataset, tokenizer):\n",
    "    tokenized_data = []\n",
    "\n",
    "    for entry in dataset:\n",
    "        # Tokenize question\n",
    "        question_tokens = tokenizer(\n",
    "            entry[\"question\"], \n",
    "            truncation=True, \n",
    "            padding=\"max_length\", \n",
    "            max_length=MAX_LENGTH_QUESTION, \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Tokenize answers\n",
    "        answer_tokens = [tokenizer(\n",
    "            ans, truncation=True, padding=\"max_length\", \n",
    "            max_length=MAX_LENGTH_ANSWER, return_tensors=\"pt\"\n",
    "        ) for ans in entry[\"answers\"]]\n",
    "\n",
    "        # Tokenize summary\n",
    "        summary_tokens = tokenizer(\n",
    "            entry[\"labelled_summary\"], \n",
    "            truncation=True, \n",
    "            padding=\"max_length\", \n",
    "            max_length=MAX_LENGTH_SUMMARY, \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Store tokenized tensors\n",
    "        tokenized_data.append({\n",
    "            \"question_input_ids\": question_tokens[\"input_ids\"].squeeze(0),\n",
    "            \"question_attention_mask\": question_tokens[\"attention_mask\"].squeeze(0),\n",
    "            \"answers_input_ids\": [ans[\"input_ids\"].squeeze(0) for ans in answer_tokens],\n",
    "            \"answers_attention_mask\": [ans[\"attention_mask\"].squeeze(0) for ans in answer_tokens],\n",
    "            \"summary_input_ids\": summary_tokens[\"input_ids\"].squeeze(0),\n",
    "            \"summary_attention_mask\": summary_tokens[\"attention_mask\"].squeeze(0),\n",
    "        })\n",
    "\n",
    "    return tokenized_data\n",
    "\n",
    "# Apply final tokenization\n",
    "final_train = tokenize_for_training(train_data, bert_tokenizer)\n",
    "final_valid = tokenize_for_training(valid_data, bert_tokenizer)\n",
    "final_test = tokenize_for_training(test_data, bert_tokenizer)\n",
    "\n",
    "# Save as PyTorch tensors\n",
    "torch.save(final_train, \"final_train.pt\")\n",
    "torch.save(final_valid, \"final_valid.pt\")\n",
    "torch.save(final_test, \"final_test.pt\")\n",
    "\n",
    "print(\"Final tokenization complete! Processed datasets saved as PyTorch tensors.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6810506-22d6-4f6b-abbf-be96c4c3cc24",
   "metadata": {},
   "source": [
    "# Fine Tuning BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d554a99-9673-4d6d-bdbb-b2063cd04e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_4620\\208085258.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_data = torch.load(\"final_train.pt\")\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_4620\\208085258.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  valid_data = torch.load(\"final_valid.pt\")\n",
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.0132\n",
      "Epoch 2: Loss = 0.0002\n",
      "Epoch 3: Loss = 0.0001\n",
      "âœ… Model training complete! Model saved as extractive_bert.pth\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, AdamW\n",
    "\n",
    "# Load tokenized dataset\n",
    "train_data = torch.load(\"final_train.pt\")\n",
    "valid_data = torch.load(\"final_valid.pt\")\n",
    "\n",
    "# Define a Custom Dataset Class\n",
    "class ExtractiveDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        return {\n",
    "            \"input_ids\": item[\"question_input_ids\"],\n",
    "            \"attention_mask\": item[\"question_attention_mask\"],\n",
    "            \"answer_ids\": item[\"answers_input_ids\"][0],  # Use first answer\n",
    "            \"answer_mask\": item[\"answers_attention_mask\"][0],\n",
    "            \"labels\": torch.ones_like(item[\"answers_input_ids\"][0])  # Assume all tokens are important for now\n",
    "        }\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 8\n",
    "train_dataset = ExtractiveDataset(train_data)\n",
    "valid_dataset = ExtractiveDataset(valid_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define Extractive Summarization Model\n",
    "class ExtractiveBERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExtractiveBERT, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 1)  # Binary Classification (Important/Not Important)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = self.classifier(outputs.last_hidden_state).squeeze(-1)  # Shape: (batch_size, seq_len)\n",
    "        return logits\n",
    "\n",
    "# Initialize Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ExtractiveBERT().to(device)\n",
    "\n",
    "# Loss & Optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, valid_loader, epochs=3):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"answer_ids\"].to(device)\n",
    "            attention_mask = batch[\"answer_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].float().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# Start Training\n",
    "train_model(model, train_loader, valid_loader, epochs=3)\n",
    "\n",
    "# Save Model\n",
    "torch.save(model.state_dict(), \"extractive_bert.pth\")\n",
    "print(\"âœ… Model training complete! Model saved as extractive_bert.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec73f5d-20d4-408b-9605-2e020ef8cbb3",
   "metadata": {},
   "source": [
    "# Code for Extractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "739da7b9-6fb7-4fd7-b0aa-0adc7c745c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Available keys in test_data: dict_keys(['question_input_ids', 'question_attention_mask', 'answers_input_ids', 'answers_attention_mask', 'summary_input_ids', 'summary_attention_mask'])\n",
      "\n",
      "âœ… Using `summary_input_ids` as the reference summary key.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17352\\3397230030.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"answer_ids\": torch.tensor(item[\"answers_input_ids\"][0]),\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17352\\3397230030.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"answer_mask\": torch.tensor(item[\"answers_attention_mask\"][0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ **ROUGE Evaluation Results:**\n",
      "âœ… ROUGE-1: 0.2006\n",
      "âœ… ROUGE-2: 0.0847\n",
      "âœ… ROUGE-L: 0.1479\n",
      "\n",
      "ðŸ“Œ **Precision-Recall Evaluation:**\n",
      "âœ… Precision: 0.2746\n",
      "âœ… Recall: 0.1517\n",
      "âœ… F1-Score: 0.1735\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from rouge_score import rouge_scorer\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "\n",
    "nltk.download(\"punkt\")  # Ensure sentence tokenizer is available\n",
    "\n",
    "# Load trained model\n",
    "class ExtractiveBERT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExtractiveBERT, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = self.classifier(outputs.last_hidden_state).squeeze(-1)\n",
    "        return logits\n",
    "\n",
    "# Define ExtractiveDataset class\n",
    "class ExtractiveDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        return {\n",
    "            \"answer_ids\": torch.tensor(item[\"answers_input_ids\"][0]),\n",
    "            \"answer_mask\": torch.tensor(item[\"answers_attention_mask\"][0])\n",
    "        }\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ExtractiveBERT().to(device)\n",
    "model.load_state_dict(torch.load(\"extractive_bert.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Load test dataset\n",
    "test_data = torch.load(\"final_test.pt\")\n",
    "\n",
    "# Check available keys in test data\n",
    "print(\"\\nâœ… Available keys in test_data:\", test_data[0].keys())\n",
    "\n",
    "# Identify the correct key for human-written summaries\n",
    "summary_key = None\n",
    "for key in [\"summary_input_ids\", \"labelled_summaries\", \"summary\"]:\n",
    "    if key in test_data[0]:\n",
    "        summary_key = key\n",
    "        break\n",
    "\n",
    "if not summary_key:\n",
    "    raise KeyError(\"âŒ No valid summary key found in test dataset!\")\n",
    "\n",
    "print(f\"\\nâœ… Using `{summary_key}` as the reference summary key.\")\n",
    "\n",
    "# Define DataLoader\n",
    "batch_size = 4\n",
    "test_dataset = ExtractiveDataset(test_data)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Sentence-Level Extraction Function\n",
    "def extract_sentences(model, test_loader, threshold=0.7):\n",
    "    model.eval()\n",
    "    extracted_summaries = []\n",
    "\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"answer_ids\"].to(device)\n",
    "        attention_mask = batch[\"answer_mask\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids, attention_mask)\n",
    "\n",
    "        # Convert logits to probabilities\n",
    "        probs = torch.sigmoid(logits)\n",
    "\n",
    "        for i in range(len(input_ids)):\n",
    "            full_text = bert_tokenizer.decode(input_ids[i], skip_special_tokens=True)\n",
    "\n",
    "            # Token Importance Scores\n",
    "            token_importance = probs[i].cpu().numpy()\n",
    "\n",
    "            # Convert text to sentences\n",
    "            sentences = sent_tokenize(full_text)\n",
    "\n",
    "            # Compute average importance score per sentence\n",
    "            sentence_scores = []\n",
    "            start = 0\n",
    "            for sent in sentences:\n",
    "                token_count = len(bert_tokenizer.encode(sent, add_special_tokens=False))\n",
    "                avg_score = np.mean(token_importance[start : start + token_count])  # Avg importance\n",
    "                sentence_scores.append((sent, avg_score))\n",
    "                start += token_count\n",
    "\n",
    "            # Sort sentences by importance & select top N%\n",
    "            sentence_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_sentences = [sent for sent, score in sentence_scores[: max(1, len(sentences) // 2)]]\n",
    "\n",
    "            extracted_summaries.append(\" \".join(top_sentences))\n",
    "\n",
    "    return extracted_summaries\n",
    "\n",
    "# Extract Key Sentences\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "extracted_sentences = extract_sentences(model, test_loader, threshold=0.7)\n",
    "\n",
    "# Compute ROUGE Scores\n",
    "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "\n",
    "rouge_scores = []\n",
    "for i in range(len(test_data)):\n",
    "    reference_summary = (\n",
    "        bert_tokenizer.decode(test_data[i][summary_key], skip_special_tokens=True)\n",
    "        if \"input_ids\" in summary_key else test_data[i][summary_key]\n",
    "    )\n",
    "    predicted_summary = extracted_sentences[i]  # Model output\n",
    "    scores = scorer.score(reference_summary, predicted_summary)\n",
    "    rouge_scores.append(scores)\n",
    "\n",
    "# Compute Average ROUGE Scores\n",
    "avg_rouge_1 = np.mean([score[\"rouge1\"].fmeasure for score in rouge_scores])\n",
    "avg_rouge_2 = np.mean([score[\"rouge2\"].fmeasure for score in rouge_scores])\n",
    "avg_rouge_l = np.mean([score[\"rougeL\"].fmeasure for score in rouge_scores])\n",
    "\n",
    "print(f\"\\nðŸ“Œ **ROUGE Evaluation Results:**\")\n",
    "print(f\"âœ… ROUGE-1: {avg_rouge_1:.4f}\")\n",
    "print(f\"âœ… ROUGE-2: {avg_rouge_2:.4f}\")\n",
    "print(f\"âœ… ROUGE-L: {avg_rouge_l:.4f}\")\n",
    "\n",
    "# Compute Precision, Recall, F1-Score\n",
    "def compute_precision_recall(true_labels, predicted_labels):\n",
    "    precisions, recalls, f1s = [], [], []\n",
    "\n",
    "    for true, pred in zip(true_labels, predicted_labels):\n",
    "        true_tokens = set(true.split())\n",
    "        pred_tokens = set(pred.split())\n",
    "\n",
    "        precision = len(true_tokens & pred_tokens) / len(pred_tokens) if len(pred_tokens) > 0 else 0\n",
    "        recall = len(true_tokens & pred_tokens) / len(true_tokens) if len(true_tokens) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "\n",
    "    return np.mean(precisions), np.mean(recalls), np.mean(f1s)\n",
    "\n",
    "# Compute Precision, Recall, and F1-Score\n",
    "precision, recall, f1_score = compute_precision_recall(\n",
    "    [\n",
    "        bert_tokenizer.decode(test_data[i][summary_key], skip_special_tokens=True)\n",
    "        if \"input_ids\" in summary_key else test_data[i][summary_key]\n",
    "        for i in range(len(test_data))\n",
    "    ], \n",
    "    extracted_sentences\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ“Œ **Precision-Recall Evaluation:**\")\n",
    "print(f\"âœ… Precision: {precision:.4f}\")\n",
    "print(f\"âœ… Recall: {recall:.4f}\")\n",
    "print(f\"âœ… F1-Score: {f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c596bc-dbc4-4fe2-a759-8a61a1f18fce",
   "metadata": {},
   "source": [
    "# Extractive Summary Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8893002-2fff-4c8e-8f0a-cd42863f19ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8396\\21076055.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(item[\"answers_input_ids\"][0]).unsqueeze(0).to(device)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8396\\21076055.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(item[\"answers_attention_mask\"][0]).unsqueeze(0).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… T5 input-output pairs saved as train_t5.json and valid_t5.json\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Load tokenizer\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Load trained BERT extractor\n",
    "class ExtractiveBERT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExtractiveBERT, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = self.classifier(outputs.last_hidden_state).squeeze(-1)\n",
    "        return logits\n",
    "\n",
    "# Load model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ExtractiveBERT().to(device)\n",
    "model.load_state_dict(torch.load(\"extractive_bert.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Sentence-level extraction function (used for T5 input)\n",
    "def extract_sentences_for_t5(data):\n",
    "    extracted_pairs = []\n",
    "\n",
    "    for item in data:\n",
    "        input_ids = torch.tensor(item[\"answers_input_ids\"][0]).unsqueeze(0).to(device)\n",
    "        attention_mask = torch.tensor(item[\"answers_attention_mask\"][0]).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            probs = torch.sigmoid(logits).squeeze(0).cpu().numpy()\n",
    "\n",
    "        full_text = bert_tokenizer.decode(input_ids.squeeze(0), skip_special_tokens=True)\n",
    "        sentences = sent_tokenize(full_text)\n",
    "\n",
    "        sentence_scores = []\n",
    "        start = 0\n",
    "        for sent in sentences:\n",
    "            token_count = len(bert_tokenizer.encode(sent, add_special_tokens=False))\n",
    "            avg_score = probs[start:start + token_count].mean() if token_count > 0 else 0\n",
    "            sentence_scores.append((sent, avg_score))\n",
    "            start += token_count\n",
    "\n",
    "        # Select top 50% most relevant sentences\n",
    "        sentence_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_sentences = [sent for sent, _ in sentence_scores[: max(1, len(sentences) // 2)]]\n",
    "        extracted_text = \" \".join(top_sentences)\n",
    "\n",
    "        # Reference summary\n",
    "        if \"summary_input_ids\" in item:\n",
    "            reference = bert_tokenizer.decode(item[\"summary_input_ids\"], skip_special_tokens=True)\n",
    "        else:\n",
    "            continue  # skip if summary is missing\n",
    "\n",
    "        extracted_pairs.append({\"input\": extracted_text, \"target\": reference})\n",
    "\n",
    "    return extracted_pairs\n",
    "\n",
    "# Load and process train and valid sets\n",
    "train_data = torch.load(\"final_train.pt\")\n",
    "valid_data = torch.load(\"final_valid.pt\")\n",
    "\n",
    "train_pairs = extract_sentences_for_t5(train_data)\n",
    "valid_pairs = extract_sentences_for_t5(valid_data)\n",
    "\n",
    "# Save for T5 fine-tuning\n",
    "with open(\"train_t5.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(train_pairs, f, indent=2)\n",
    "\n",
    "with open(\"valid_t5.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(valid_pairs, f, indent=2)\n",
    "\n",
    "print(\"âœ… T5 input-output pairs saved as train_t5.json and valid_t5.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4932677b-d710-47dd-b2f4-9cd2e11c8f1a",
   "metadata": {},
   "source": [
    "# Fine-Tune T5-small for Abstractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c20ce4f-4e79-496c-9ce9-f7eeb91046aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad1b83927e849c8891900dfff1dee02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2236 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3970: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22924046ff804d4c82b4576adc5248f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/959 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_4992\\581530843.py:71: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = CustomTrainer(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2795' max='2795' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2795/2795 3:29:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.553800</td>\n",
       "      <td>1.485477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.633600</td>\n",
       "      <td>1.457912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.299300</td>\n",
       "      <td>1.445072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.377800</td>\n",
       "      <td>1.447244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.455300</td>\n",
       "      <td>1.443088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… T5 fine-tuning complete. Model saved to 't5_summarizer/'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and prepare data\n",
    "with open(\"train_t5.json\", \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open(\"valid_t5.json\", \"r\") as f:\n",
    "    valid_data = json.load(f)\n",
    "\n",
    "dataset = Dataset.from_list(train_data)\n",
    "val_dataset = Dataset.from_list(valid_data)\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(example):\n",
    "    model_input = tokenizer(example[\"input\"], max_length=256, truncation=True, padding=\"max_length\")\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(example[\"target\"], max_length=128, truncation=True, padding=\"max_length\")\n",
    "    model_input[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_input\n",
    "\n",
    "# Tokenize datasets\n",
    "train_dataset = dataset.map(preprocess)\n",
    "valid_dataset = val_dataset.map(preprocess)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"t5_summarizer\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=10,\n",
    "    logging_dir=\"logs\",\n",
    "    logging_steps=20,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Store training loss manually\n",
    "class LossRecorder:\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.eval_losses = []\n",
    "\n",
    "    def callback(self, logs):\n",
    "        if \"loss\" in logs:\n",
    "            self.train_losses.append(logs[\"loss\"])\n",
    "        if \"eval_loss\" in logs:\n",
    "            self.eval_losses.append(logs[\"eval_loss\"])\n",
    "\n",
    "loss_recorder = LossRecorder()\n",
    "\n",
    "# Custom Trainer class to hook into log history\n",
    "class CustomTrainer(Trainer):\n",
    "    def log(self, logs, *args, **kwargs):\n",
    "        super().log(logs, *args, **kwargs)\n",
    "        loss_recorder.callback(logs)\n",
    "\n",
    "\n",
    "# Trainer setup\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save the final model\n",
    "model.save_pretrained(\"t5_summarizer\")\n",
    "tokenizer.save_pretrained(\"t5_summarizer\")\n",
    "print(\"\\nâœ… T5 fine-tuning complete. Model saved to 't5_summarizer/'\")\n",
    "\n",
    "# Plot training vs validation loss\n",
    "plt.plot(loss_recorder.train_losses, label=\"Training Loss\")\n",
    "plt.plot(loss_recorder.eval_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347833ba-dfe4-44c0-b989-a4f607fd0d4a",
   "metadata": {},
   "source": [
    "# Final Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9615225-eaab-44cc-b021-748f4e02c0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17636\\3443162528.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(item[\"answers_input_ids\"][0]).unsqueeze(0)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17636\\3443162528.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(item[\"answers_attention_mask\"][0]).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ ROUGE Scores\n",
      "âœ… ROUGE-1: 0.2066\n",
      "âœ… ROUGE-2: 0.0928\n",
      "âœ… ROUGE-L: 0.1647\n",
      "\n",
      "ðŸ“Œ BLEU Score: 0.0365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6eb30f33da404f9fb9dbacbd270de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1c1026c7e8406f9b71cc67ecae72a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 366.66 seconds, 1.75 sentences/sec\n",
      "\n",
      "ðŸ“Œ BERTScore:\n",
      "âœ… Precision: 0.6365\n",
      "âœ… Recall:    0.6175\n",
      "âœ… F1 Score:  0.6266\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from datasets import load_dataset, Dataset\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import bert_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Load fine-tuned T5 model and tokenizer\n",
    "model_path = \"t5_summarizer\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path).to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "# Load test data\n",
    "from torch.utils.data import DataLoader, Dataset as TorchDataset\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "class ExtractiveBERT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExtractiveBERT, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = self.classifier(outputs.last_hidden_state).squeeze(-1)\n",
    "        return logits\n",
    "\n",
    "# Load trained extractor\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "extractor = ExtractiveBERT().to(\"cpu\")\n",
    "extractor.load_state_dict(torch.load(\"extractive_bert.pth\", map_location=\"cpu\"))\n",
    "extractor.eval()\n",
    "\n",
    "# Load test set\n",
    "test_data = torch.load(\"final_test.pt\")\n",
    "\n",
    "# Extractive to Abstractive pipeline\n",
    "def extract_inputs_for_t5(data):\n",
    "    inputs, targets = [], []\n",
    "\n",
    "    for item in data:\n",
    "        input_ids = torch.tensor(item[\"answers_input_ids\"][0]).unsqueeze(0)\n",
    "        attention_mask = torch.tensor(item[\"answers_attention_mask\"][0]).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = extractor(input_ids, attention_mask)\n",
    "            probs = torch.sigmoid(logits).squeeze(0).numpy()\n",
    "\n",
    "        full_text = bert_tokenizer.decode(input_ids.squeeze(0), skip_special_tokens=True)\n",
    "        sentences = sent_tokenize(full_text)\n",
    "\n",
    "        sentence_scores = []\n",
    "        start = 0\n",
    "        for sent in sentences:\n",
    "            token_count = len(bert_tokenizer.encode(sent, add_special_tokens=False))\n",
    "            avg_score = probs[start:start + token_count].mean() if token_count > 0 else 0\n",
    "            sentence_scores.append((sent, avg_score))\n",
    "            start += token_count\n",
    "\n",
    "        sentence_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_sentences = [sent for sent, _ in sentence_scores[: max(1, len(sentences) // 2)]]\n",
    "        extracted = \" \".join(top_sentences)\n",
    "\n",
    "        if \"summary_input_ids\" in item:\n",
    "            ref_summary = bert_tokenizer.decode(item[\"summary_input_ids\"], skip_special_tokens=True)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        inputs.append(extracted)\n",
    "        targets.append(ref_summary)\n",
    "\n",
    "    return inputs, targets\n",
    "\n",
    "# Run extractor to get T5 inputs\n",
    "test_inputs, reference_summaries = extract_inputs_for_t5(test_data)\n",
    "\n",
    "# Generate predictions using T5\n",
    "predictions = []\n",
    "for input_text in test_inputs:\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=256, truncation=True)\n",
    "    summary_ids = model.generate(input_ids, max_length=128, num_beams=4, early_stopping=True)\n",
    "    pred = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    predictions.append(pred)\n",
    "\n",
    "# Save predictions\n",
    "with open(\"t5_test_predictions.json\", \"w\") as f:\n",
    "    json.dump([{\"input\": i, \"prediction\": p, \"reference\": r} for i, p, r in zip(test_inputs, predictions, reference_summaries)], f, indent=2)\n",
    "\n",
    "# --- Evaluation: ROUGE ---\n",
    "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "rouge_scores = [scorer.score(ref, pred) for ref, pred in zip(reference_summaries, predictions)]\n",
    "\n",
    "avg_rouge_1 = np.mean([s[\"rouge1\"].fmeasure for s in rouge_scores])\n",
    "avg_rouge_2 = np.mean([s[\"rouge2\"].fmeasure for s in rouge_scores])\n",
    "avg_rouge_l = np.mean([s[\"rougeL\"].fmeasure for s in rouge_scores])\n",
    "\n",
    "print(\"\\nðŸ“Œ ROUGE Scores\")\n",
    "print(f\"âœ… ROUGE-1: {avg_rouge_1:.4f}\")\n",
    "print(f\"âœ… ROUGE-2: {avg_rouge_2:.4f}\")\n",
    "print(f\"âœ… ROUGE-L: {avg_rouge_l:.4f}\")\n",
    "\n",
    "# --- Evaluation: BLEU ---\n",
    "bleu_scores = []\n",
    "smoother = SmoothingFunction().method4\n",
    "for ref, pred in zip(reference_summaries, predictions):\n",
    "    ref_tokens = ref.split()\n",
    "    pred_tokens = pred.split()\n",
    "    score = sentence_bleu([ref_tokens], pred_tokens, smoothing_function=smoother)\n",
    "    bleu_scores.append(score)\n",
    "\n",
    "avg_bleu = np.mean(bleu_scores)\n",
    "print(f\"\\nðŸ“Œ BLEU Score: {avg_bleu:.4f}\")\n",
    "\n",
    "# --- Evaluation: BERTScore ---\n",
    "P, R, F1 = bert_score.score(predictions, reference_summaries, lang=\"en\", verbose=True)\n",
    "print(\"\\nðŸ“Œ BERTScore:\")\n",
    "print(f\"âœ… Precision: {P.mean():.4f}\")\n",
    "print(f\"âœ… Recall:    {R.mean():.4f}\")\n",
    "print(f\"âœ… F1 Score:  {F1.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33af0c53-6399-416c-93c6-efb6990a0253",
   "metadata": {},
   "source": [
    "# Testing from user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9719278-c788-42bc-9644-c56968ac5778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ Enter a healthcare-related answer text:If you're experiencing frequent headaches along with nausea and sensitivity to light, it's possible you're suffering from migraines. These symptoms can often be triggered by stress, hormonal changes, lack of sleep, or certain foods like chocolate or aged cheese. It's important to keep a headache diary to track patterns and triggers. Over-the-counter medications like ibuprofen or acetaminophen may help, but if the headaches are severe or interfere with your daily life, you should consult a neurologist. Preventive medications and lifestyle modifications like regular exercise, hydration, and consistent sleep schedules can also make a significant difference.   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ No high-confidence sentences found. Using full input as fallback.\n",
      "Extracted Text:\n",
      "[Fallback: Full input used]\n",
      "Generated Token IDs: tensor([[0, 1]])\n",
      "Raw T5 Output (Decoded):\n",
      "[Empty Output]\n",
      "\n",
      "âœ¨ Generated Summary:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from datasets import load_dataset, Dataset\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import bert_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset as TorchDataset\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "class ExtractiveBERT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExtractiveBERT, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = self.classifier(outputs.last_hidden_state).squeeze(-1)\n",
    "        return logits\n",
    "\n",
    "# Load fine-tuned T5 model and tokenizer\n",
    "model_path = \"t5_summarizer\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path).to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "# Load trained extractor\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "extractor = ExtractiveBERT().to(\"cpu\")\n",
    "extractor.load_state_dict(torch.load(\"extractive_bert.pth\", map_location=\"cpu\"))\n",
    "extractor.eval()\n",
    "\n",
    "# Load test set\n",
    "test_data = torch.load(\"final_test.pt\")\n",
    "\n",
    "# Function for single prediction using hybrid model\n",
    "def summarize_user_input(text):\n",
    "    model.eval()\n",
    "    extractor.eval()\n",
    "\n",
    "    # Tokenize input using BERT tokenizer for extractor\n",
    "    input_ids = torch.tensor(bert_tokenizer.encode(text, max_length=512, truncation=True)).unsqueeze(0)\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "    # Run BERT extractor\n",
    "    with torch.no_grad():\n",
    "        logits = extractor(input_ids, attention_mask)\n",
    "        probs = torch.sigmoid(logits).squeeze(0).numpy()\n",
    "\n",
    "    # Sentence-level extraction\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentence_scores = []\n",
    "    start = 0\n",
    "    for sent in sentences:\n",
    "        token_count = len(bert_tokenizer.encode(sent, add_special_tokens=False))\n",
    "        avg_score = probs[start:start + token_count].mean() if token_count > 0 else 0\n",
    "        sentence_scores.append((sent, avg_score))\n",
    "        start += token_count\n",
    "\n",
    "    # Select top 80% sentences by score\n",
    "    sentence_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_sentences = [sent for sent, _ in sentence_scores[: max(1, int(0.8 * len(sentences)))]]\n",
    "    extracted_text = \" \".join(top_sentences)\n",
    "\n",
    "    if not extracted_text.strip():\n",
    "        print(\"âš ï¸ No high-confidence sentences found. Using full input as fallback.\")\n",
    "        extracted_text = text\n",
    "\n",
    "    print(\"Extracted Text:\")\n",
    "    print(extracted_text if extracted_text.strip() else \"[Fallback: Full input used]\")\n",
    "\n",
    "    # Generate summary using T5\n",
    "    extracted_text = \"summarize: \" + extracted_text\n",
    "    t5_input = tokenizer.encode(extracted_text, return_tensors=\"pt\", max_length=384, truncation=True).to(\"cpu\")\n",
    "    with torch.no_grad():\n",
    "        summary_ids = model.generate(t5_input, max_length=150, num_beams=4, early_stopping=True)\n",
    "\n",
    "    print(\"Generated Token IDs:\", summary_ids)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    print(\"Raw T5 Output (Decoded):\")\n",
    "    print(summary if summary.strip() else \"[Empty Output]\")\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "user_input = input(\"\\nðŸ“ Enter a healthcare-related answer text:If you're experiencing frequent headaches along with nausea and sensitivity to light, it's possible you're suffering from migraines. These symptoms can often be triggered by stress, hormonal changes, lack of sleep, or certain foods like chocolate or aged cheese. It's important to keep a headache diary to track patterns and triggers. Over-the-counter medications like ibuprofen or acetaminophen may help, but if the headaches are severe or interfere with your daily life, you should consult a neurologist. Preventive medications and lifestyle modifications like regular exercise, hydration, and consistent sleep schedules can also make a significant difference.  \")\n",
    "summary = summarize_user_input(user_input)\n",
    "print(\"\\nâœ¨ Generated Summary:\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914c8244-d770-4cc7-a028-fcd4c535b599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
